<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Diffusion model</title>
    <link href="/2022/04/14/DDPM/"/>
    <url>/2022/04/14/DDPM/</url>
    
    <content type="html"><![CDATA[<h2 id="diffusion-model">Diffusion model</h2><p>本篇主要总结diffusion model的学习, 主要设计DDPM这篇文章中所提出的算法.</p><h3 id="生成模型">生成模型</h3><p>生成模型的的主要目标在于找到一个概率分布<span class="math inline">\(p(x)\)</span>,其能表示数据集的所有分布.包含当前数据集中已有的和当前数据集同一分布的其他数据.这样,我们就可以通过采样<span class="math inline">\(p(x)\)</span>来生成新的数据.</p><h3 id="基于得分模型">基于得分模型</h3><p>一个朴素的想法是,</p><p><span class="math display">\[\begin{equation}p_\theta(x) = \frac{e^{-f_\theta(x)}}{Z_\theta}\end{equation}\]</span></p><p>其中<span class="math inline">\(Z_\theta\)</span>是一个归一化常量,使得<span class="math inline">\(p_\theta\)</span>为满足<span class="math inline">\(\int p_\theta (x) dx = 1\)</span>的概率密度函数.但是这里存在一个问题,<span class="math inline">\(Z_{\theta}\)</span>的取值取决于<span class="math inline">\(f_\theta (x)\)</span>, 然而计算<span class="math inline">\(Z_{\theta}\)</span>通常情况下是非常困难的.那么我们可以换另一种方式, 我们可以对概率密度函数的梯度进行建模.</p><p><span class="math display">\[\begin{equation}s_\theta (x) = \nabla_x log \, p_\theta(x) = \nabla_x f_\theta (x) - \nabla_x log \, Z_{\theta} = -\nabla_x f_\theta (x)\end{equation}\]</span></p><p>这样,我们可以不用再考虑<span class="math inline">\(\theta\)</span> 带来的归一化计算问题.</p><p>在采样生成新的样本的时候,我们可以通过 langevin dynamics采样. langevin dynamics 仅使用<span class="math inline">\(\nabla_x log \, p(x)\)</span>来从<span class="math inline">\(p(x)\)</span>分布中采样.其过程为:</p><p><span class="math display">\[\begin{equation}x_{i+1} \leftarrow x_i + \epsilon \nabla_x log \, p(x) + \sqrt{2 \epsilon } z_i \end{equation}\]</span></p><p>其中<span class="math inline">\(z_i \sim N(0,1)\)</span>, <span class="math inline">\(i\rightarrow \infty, \epsilon \rightarrow 0\)</span>,我们得到一个<span class="math inline">\(p(x)\)</span>的采样,在这里,我们可以使用<span class="math inline">\(s_\theta(x)\)</span>来代替<span class="math inline">\(\nabla_x log \, p(x)\)</span>,从而进行采样.</p><h3 id="缺陷">缺陷</h3><p><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/smld.jpg" alt="img" style="zoom:20%;" /></p><p>这里看似很美好,但存在着一个比较大的问题.在所给数据集的低密度区域,分数函数的估计是不准确的,这会导致很难生成高质量的样本.</p><h3 id="解决方式">解决方式</h3><p>既然问题出在低密度区域的估计上,那么我们是不是可以人为的填充低密度区域,使其在所有地方都估计准确呢.这里就可以在我们的样本上叠加足够的噪声,当噪声的幅值足够大时,数据空间中将不会再有低密度区域.又引出另一个问题,如何控制噪声的大小呢.当噪声较小时,不能达到我们想要覆盖整个空间的效果, 而当噪声过大时,又会破坏原始数据的分布.</p><p>使用一系列不同尺度的噪声进行扰动, 可以综合解决以上两个问题.这里的解决方式,实际上就已经引出我们要介绍的模型,<strong>DDPM</strong>.</p><h3 id="ddpm">DDPM</h3><ol type="1"><li><p><strong>前向过程</strong></p><p>前向过程就是我们节所说的,对样本添加一系列不同尺度的噪声.对于一个数据<span class="math inline">\(x_0 \sim q(x)\)</span>,我们在<span class="math inline">\(T\)</span>步内对其添加一系列高斯噪声,得到一个加噪序列<span class="math inline">\(x_1, ... x_T\)</span>.每步添加的噪声大小,由超参数<span class="math inline">\(\beta_t \in (0,1)\)</span>控制.</p><p><span class="math display">\[\begin{equation}q(x_t|x_{t-1}) = N(x_t;\sqrt{1-\beta_t}x_{t-1}, \beta_t I)\end{equation}\]</span></p><p><span class="math display">\[\begin{equation}q(x_{1:T}|x_0) = \prod_{t=1}^{T}{q(x_t|x_{t-1})}\end{equation}\]</span></p><p>加噪数据<span class="math inline">\(x_t\)</span>随着<span class="math inline">\(t\)</span>的增加,逐渐变为一个高斯噪声.</p><p><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/DDPM.png" alt="img" style="zoom:15%;" /></p><p>对于上述过程,我们使用重参数技巧,可以很好的进行合并,使得可以一步计算出t步的加噪图像.</p><blockquote><h3 id="重参数技巧">重参数技巧</h3><p>这里我们回顾一下重参数技巧,他在VAE中也有用到,用来从一个分布中采样,同时保持梯度.</p><p>假设我们需要采样<span class="math inline">\(q(x_t|x_{t-1}) = N(x_t;\sqrt{1-\beta_t}x_{t-1}, \beta_t I)\)</span>,我们可以取一个变量<span class="math inline">\(z \sim N(0,1)\)</span>,根据高斯分布的特性,不同高斯分布数据之间转移关系为<span class="math inline">\(\mu + \sigma z\)</span>, 可以得到</p><p><span class="math display">\[x_t = \sqrt{1-\beta_t}x_{t-1} + \sqrt{\beta_t} z \]</span></p></blockquote><p><span class="math display">\[\begin{equation}\begin{aligned} x_t &amp;= \sqrt{\alpha_t}x_{t-1} + \sqrt{1 - \alpha_t}z_{t-1} &amp; \text{ ;where } z_{t-1}, z_{t-2}, \dots \sim {N}({0}, {I}) \\ &amp;= \color{blue}{\sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_{t-1}}z_{t-2}) + \sqrt{1 - \alpha_t}z_{t-1}}\\ &amp;= \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \bar z_{t-2} &amp; \text{ ;where } \bar z_{t-2} \text{ merges two Gaussians (*).} \\ &amp;= \dots \\ &amp;= \sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}z \\ \end{aligned}\end{equation}\]</span></p><p><span class="math display">\[\begin{equation}q(x_t \vert x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t){I}) \end{equation}\]</span></p><p>其中<span class="math inline">\(\alpha_t = 1- \beta_t, \bar{\alpha_t} = \prod_{i=1}^{T} \alpha_i\)</span></p></li><li><p><strong>反向过程</strong></p><p>正向过程添加噪声,那么我们只要在反向时,去除噪声,就能得到原始数据.我们利用<span class="math inline">\(q(x_{t-1}|x_t)\)</span>从高斯噪声<span class="math inline">\(x_T\)</span>,经过不断去噪,最终能重建真实样本.但是,我们无法直接得到<span class="math inline">\(q(x_{t-1}|x_t)\)</span>. 类似于VAE中的encoder,我们学习一个模型<span class="math inline">\(p_{\theta}\)</span>来估计,也就是 <span class="math inline">\(q(x_{t-1}|x_t) \sim p_θ(x_{t-1}|x_t)\)</span>.</p><p>在<span class="math inline">\(\beta_t\)</span>很小的情况下, <span class="math inline">\(p_θ(x_{t-1}|x_t)\)</span>依然为高斯分布,即有:</p><p><span class="math display">\[\begin{equation}p_θ(x_{t-1}|x_t) = N(x_{t-1}; \mu_{\theta}(x_t,t), \sum_{\theta}(x_t, t))\end{equation}\]</span></p><p>在条件<span class="math inline">\(x_0\)</span>时,有:</p><p><span class="math display">\[\begin{equation}q(x_{t-1}|x_t, x_0) = N(x_{t-1};\tilde{\mu}(x_t,x_0),\tilde{\beta_t}I)\end{equation}\]</span></p><p>我们利用贝叶斯公式,得到:</p><p><span class="math display">\[\begin{equation}\begin{aligned}q(x_{t-1}|x_t, x_0) &amp;= q(x_t|x_{t-1}, x_0)\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} \\             &amp;=N(x_t; \sqrt(\alpha_t) x_{t-1}, \beta_t) \frac{N(x_{t-1}; \sqrt(\bar{\alpha_{t-1})} x_0, (1-\bar{\alpha_{t-1}}))}{N(x_t; \sqrt(\bar{\alpha_t}) x_0, (1-\bar{\alpha_{t}}))} \\             &amp;\propto \exp \Big(-\frac{1}{2} \big(\frac{(\mathbf x_t - \sqrt{\alpha_t} \mathbf x_{t-1})^2}{\beta_t} + \frac{(\mathbf x_{t-1} - \sqrt{\bar \alpha_{t-1}} \mathbf x_0)^2}{1-\bar \alpha_{t-1}} - \frac{(\mathbf x_t - \sqrt{\bar \alpha_t} \mathbf x_0)^2}{1-\bar \alpha_t} \big) \Big) \\              &amp;= \exp\Big( -\frac{1}{2} \big( \color{red}{(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar \alpha_{t-1}})} \mathbf x_{t-1}^2 - \color{blue}{(\frac{2\sqrt{\alpha_t}}{\beta_t} \mathbf x_t + \frac{2\sqrt{\bar \alpha_t}}{1 - \bar \alpha_t} \mathbf x_0)} \mathbf x_{t-1} + C(\mathbf x_t, \mathbf x_0) \big) \Big)  \end{aligned}\end{equation}\]</span></p><p>其中<span class="math inline">\(C(x_t, x_0)\)</span>不涉及<span class="math inline">\(x_{t-1}\)</span>,可以认为对标准高斯分布的均值方差无影响,可以省略.根据标准的高斯密度函数,我们可以得到其中<span class="math inline">\(\tilde{\mu}(x_t,x_0),\tilde{\beta_t}\)</span>的表达式</p><p><span class="math display">\[\begin{equation} \tilde{\mu}(\mathbf x_t,\mathbf x_0) = 1/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar \alpha_{t-1}}) = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_{t}} \cdot \beta_t  \end{equation}\]</span></p><p><span class="math display">\[\begin{equation}\tilde \mu_t (\mathbf x_t, \mathbf x_0) = (\frac{\sqrt{\alpha_t}}{\beta_t} \mathbf x_t + \frac{\sqrt{\bar \alpha_t}}{1 - \bar \alpha_t} \mathbf x_0)/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar \alpha_{t-1}}) = \frac{\sqrt{\alpha_t}(1 - \bar \alpha_{t-1})}{1 - \bar \alpha_t} \mathbf x_t + \frac{\sqrt{\bar \alpha_{t-1}}\beta_t}{1 - \bar \alpha_t} \mathbf x_0 \end{equation}\]</span></p><p>我们根据前向过程的计算公式,可以知道<span class="math inline">\(\mathbf{x}_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\mathbf{z }_t)\)</span>.将其带入上式中,可以得到:</p><p><span class="math display">\[\begin{equation}\begin{aligned}\tilde{\boldsymbol{\mu}}_t&amp;= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\mathbf{z}_t) \\&amp;= \color{cyan}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_t \Big)}\end{aligned}\end{equation}\]</span></p><p>再次回顾一下,我们最初的想法是拿<span class="math inline">\(p_θ(x_{t-1}|x_t)\)</span> 估计<span class="math inline">\(q(x_{t-1}|x_t)\)</span>, 推导后我们可以看到,我们可以仅仅估计<span class="math inline">\(z_t\)</span>就能达到这个目的.(因为其他的都是常量).实际上,下节的Loss推导过程中,最后也得出来这样计算loss较为简单.</p></li><li><p><strong>Loss计算</strong></p><p>我们的目标是最大化似然函数: <span class="math display">\[\begin{equation}\begin{aligned}-\log p_\theta(\mathbf{x}_0) &amp;\leq - \log p_\theta(\mathbf{x}_0) + D_\text{KL}(q(\mathbf{x}_{1:T}\vert\mathbf{x}_0) \| p_\theta(\mathbf{x}_{1:T}\vert\mathbf{x}_0) ) \\-&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_{\mathbf{x}_{1:T}\sim q(\mathbf{x}_{1:T} \vert \mathbf{x}_0)} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T}) / p_\theta(\mathbf{x}_0)} \Big] \\&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_q \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} + \log p_\theta(\mathbf{x}_0) \Big] \\&amp;= \mathbb{E}_q \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\\text{Let }L_\text{VLB} &amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \geq - \mathbb{E}_{q(\mathbf{x}_0)} \log p_\theta(\mathbf{x}_0)\end{aligned}\end{equation}\]</span></p><p>为将上述方程的每项都转变为可计算的,可以将其重写为几个KL散度的组合.</p><p><span class="math display">\[\begin{equation}\begin{aligned}L_\text{VLB} &amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\&amp;= \mathbb{E}_q \Big[ \log\frac{\prod_{t=1}^T q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{ p_\theta(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t) } \Big] \\&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=1}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} \Big] \\&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \Big( \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)}\cdot \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1}\vert\mathbf{x}_0)} \Big) + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1} \vert \mathbf{x}_0)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{q(\mathbf{x}_1 \vert \mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big]\\&amp;= \mathbb{E}_q \Big[ \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_T)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} - \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1) \Big] \\&amp;= \mathbb{E}_q [\underbrace{D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T))}_{L_T} + \sum_{t=2}^T \underbrace{D_\text{KL}(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t))}_{L_{t-1}} \underbrace{- \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)}_{L_0} ]\end{aligned}\end{equation}\]</span> 其中<span class="math inline">\(L_T\)</span>为常数项,因为<span class="math inline">\(q(x_T|x_0)\)</span>没有参数.</p><p>对于<span class="math inline">\(L_t\)</span>项:</p><p><span class="math display">\[\begin{equation}\begin{aligned}L_t &amp;= \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \Big[\frac{1}{2 \| \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t) \|^2_2} \| \color{blue}{\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0)} - \color{green}{\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)} \|^2 \Big] \\&amp;= \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \Big[\frac{1}{2  \|\boldsymbol{\Sigma}_\theta \|^2_2} \| \color{blue}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_t \Big)} - \color{green}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\mathbf{z}}_\theta(\mathbf{x}_t, t) \Big)} \|^2 \Big] \\&amp;= \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \Big[\frac{ \beta_t^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \| \boldsymbol{\Sigma}_\theta \|^2_2} \|\mathbf{z}_t - \mathbf{z}_\theta(\mathbf{x}_t, t)\|^2 \Big] \\&amp;= \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \Big[\frac{ \beta_t^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \| \boldsymbol{\Sigma}_\theta \|^2_2} \|\mathbf{z}_t - \mathbf{z}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\mathbf{z}_t, t)\|^2 \Big] \end{aligned}\end{equation}\]</span></p><p>忽略其加权项,得到简化的loss <span class="math display">\[\begin{equation}L_t^\text{simple} = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}_t} \Big[\|\mathbf{z}_t - \mathbf{z}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\mathbf{z}_t, t)\|^2 \Big]\end{equation}\]</span></p></li><li><p><strong>直观理解</strong></p><p>直观上,我们可以把<span class="math inline">\(p_θ(x_{t-1}|x_t)\)</span> 理解为利用一个模型根据加噪图像去预测其噪声,然后我们计算预测出的噪声和原本加入的噪声的mse loss.</p></li><li><p><strong>代码</strong></p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DenoiseDiffusion</span>:</span>    <span class="hljs-string">&quot;&quot;&quot;</span><span class="hljs-string">    ## Denoise Diffusion</span><span class="hljs-string">    &quot;&quot;&quot;</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, eps_model: nn.Module, n_steps: <span class="hljs-built_in">int</span>, device: torch.device</span>):</span>        <span class="hljs-string">&quot;&quot;&quot;</span><span class="hljs-string">        * `eps_model` is $\textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(x_t, t)$ model</span><span class="hljs-string">        * `n_steps` is $t$</span><span class="hljs-string">        * `device` is the device to place constants on</span><span class="hljs-string">        &quot;&quot;&quot;</span>        <span class="hljs-built_in">super</span>().__init__()        self.eps_model = eps_model        <span class="hljs-comment"># Create $\beta_1, \dots, \beta_T$ linearly increasing variance schedule</span>        self.beta = torch.linspace(<span class="hljs-number">0.0001</span>, <span class="hljs-number">0.02</span>, n_steps).to(device)        <span class="hljs-comment"># $\alpha_t = 1 - \beta_t$</span>        self.alpha = <span class="hljs-number">1.</span> - self.beta        <span class="hljs-comment"># $\bar\alpha_t = \prod_&#123;s=1&#125;^t \alpha_s$</span>        self.alpha_bar = torch.cumprod(self.alpha, dim=<span class="hljs-number">0</span>)        <span class="hljs-comment"># $T$</span>        self.n_steps = n_steps        <span class="hljs-comment"># $\sigma^2 = \beta$</span>        self.sigma2 = self.beta    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">q_xt_x0</span>(<span class="hljs-params">self, x0: torch.Tensor, t: torch.Tensor</span>) -&gt; Tuple[torch.Tensor, torch.Tensor]:</span>        <span class="hljs-string">&quot;&quot;&quot;</span><span class="hljs-string">        #### Get $q(x_t|x_0)$ distribution</span><span class="hljs-string">        \begin&#123;align&#125;</span><span class="hljs-string">        q(x_t|x_0) &amp;= \mathcal&#123;N&#125; \Big(x_t; \sqrt&#123;\bar\alpha_t&#125; x_0, (1-\bar\alpha_t) \mathbf&#123;I&#125; \Big)</span><span class="hljs-string">        \end&#123;align&#125;</span><span class="hljs-string">        &quot;&quot;&quot;</span>        <span class="hljs-comment"># [gather](utils.html) $\alpha_t$ and compute $\sqrt&#123;\bar\alpha_t&#125; x_0$</span>        mean = gather(self.alpha_bar, t) ** <span class="hljs-number">0.5</span> * x0        <span class="hljs-comment"># $(1-\bar\alpha_t) \mathbf&#123;I&#125;$</span>        var = <span class="hljs-number">1</span> - gather(self.alpha_bar, t)        <span class="hljs-comment">#</span>        <span class="hljs-keyword">return</span> mean, var    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">q_sample</span>(<span class="hljs-params">self, x0: torch.Tensor, t: torch.Tensor, eps: Optional[torch.Tensor] = <span class="hljs-literal">None</span></span>):</span>        <span class="hljs-string">&quot;&quot;&quot;</span><span class="hljs-string">        #### Sample from $q(x_t|x_0)$</span><span class="hljs-string">        \begin&#123;align&#125;</span><span class="hljs-string">        q(x_t|x_0) &amp;= \mathcal&#123;N&#125; \Big(x_t; \sqrt&#123;\bar\alpha_t&#125; x_0, (1-\bar\alpha_t) \mathbf&#123;I&#125; \Big)</span><span class="hljs-string">        \end&#123;align&#125;</span><span class="hljs-string">        &quot;&quot;&quot;</span>        <span class="hljs-comment"># $\epsilon \sim \mathcal&#123;N&#125;(\mathbf&#123;0&#125;, \mathbf&#123;I&#125;)$</span>        <span class="hljs-keyword">if</span> eps <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:            eps = torch.randn_like(x0)        <span class="hljs-comment"># get $q(x_t|x_0)$</span>        mean, var = self.q_xt_x0(x0, t)        <span class="hljs-comment"># Sample from $q(x_t|x_0)$</span>        <span class="hljs-keyword">return</span> mean + (var ** <span class="hljs-number">0.5</span>) * eps    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">p_sample</span>(<span class="hljs-params">self, xt: torch.Tensor, t: torch.Tensor</span>):</span>        <span class="hljs-string">&quot;&quot;&quot;</span><span class="hljs-string">        #### Sample from $\textcolor&#123;cyan&#125;&#123;p_\theta&#125;(x_&#123;t-1&#125;|x_t)$</span><span class="hljs-string">        \begin&#123;align&#125;</span><span class="hljs-string">        \textcolor&#123;cyan&#125;&#123;p_\theta&#125;(x_&#123;t-1&#125; | x_t) &amp;= \mathcal&#123;N&#125;\big(x_&#123;t-1&#125;;</span><span class="hljs-string">        \textcolor&#123;cyan&#125;&#123;\mu_\theta&#125;(x_t, t), \sigma_t^2 \mathbf&#123;I&#125; \big) \\</span><span class="hljs-string">        \textcolor&#123;cyan&#125;&#123;\mu_\theta&#125;(x_t, t)</span><span class="hljs-string">          &amp;= \frac&#123;1&#125;&#123;\sqrt&#123;\alpha_t&#125;&#125; \Big(x_t -</span><span class="hljs-string">            \frac&#123;\beta_t&#125;&#123;\sqrt&#123;1-\bar\alpha_t&#125;&#125;\textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(x_t, t) \Big)</span><span class="hljs-string">        \end&#123;align&#125;</span><span class="hljs-string">        &quot;&quot;&quot;</span>        <span class="hljs-comment"># $\textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(x_t, t)$</span>        eps_theta = self.eps_model(xt, t)        <span class="hljs-comment"># [gather](utils.html) $\bar\alpha_t$</span>        alpha_bar = gather(self.alpha_bar, t)        <span class="hljs-comment"># $\alpha_t$</span>        alpha = gather(self.alpha, t)        <span class="hljs-comment"># $\frac&#123;\beta&#125;&#123;\sqrt&#123;1-\bar\alpha_t&#125;&#125;$</span>        eps_coef = (<span class="hljs-number">1</span> - alpha) / (<span class="hljs-number">1</span> - alpha_bar) ** <span class="hljs-number">.5</span>        <span class="hljs-comment"># $$\frac&#123;1&#125;&#123;\sqrt&#123;\alpha_t&#125;&#125; \Big(x_t -</span>        <span class="hljs-comment">#      \frac&#123;\beta_t&#125;&#123;\sqrt&#123;1-\bar\alpha_t&#125;&#125;\textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(x_t, t) \Big)$$</span>        mean = <span class="hljs-number">1</span> / (alpha ** <span class="hljs-number">0.5</span>) * (xt - eps_coef * eps_theta)        <span class="hljs-comment"># $\sigma^2$</span>        var = gather(self.sigma2, t)        <span class="hljs-comment"># $\epsilon \sim \mathcal&#123;N&#125;(\mathbf&#123;0&#125;, \mathbf&#123;I&#125;)$</span>        eps = torch.randn(xt.shape, device=xt.device)        <span class="hljs-comment"># Sample</span>        <span class="hljs-keyword">return</span> mean + (var ** <span class="hljs-number">.5</span>) * eps    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loss</span>(<span class="hljs-params">self, x0: torch.Tensor, noise: Optional[torch.Tensor] = <span class="hljs-literal">None</span></span>):</span>        <span class="hljs-string">&quot;&quot;&quot;</span><span class="hljs-string">        #### Simplified Loss</span><span class="hljs-string">        $$L_simple(\theta) = \mathbb&#123;E&#125;_&#123;t,x_0, \epsilon&#125; \Bigg[ \bigg\Vert</span><span class="hljs-string">        \epsilon - \textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(\sqrt&#123;\bar\alpha_t&#125; x_0 + \sqrt&#123;1-\bar\alpha_t&#125;\epsilon, t)</span><span class="hljs-string">        \bigg\Vert^2 \Bigg]$$</span><span class="hljs-string">        &quot;&quot;&quot;</span>        <span class="hljs-comment"># Get batch size</span>        batch_size = x0.shape[<span class="hljs-number">0</span>]        <span class="hljs-comment"># Get random $t$ for each sample in the batch</span>        t = torch.randint(<span class="hljs-number">0</span>, self.n_steps, (batch_size,), device=x0.device, dtype=torch.long)        <span class="hljs-comment"># $\epsilon \sim \mathcal&#123;N&#125;(\mathbf&#123;0&#125;, \mathbf&#123;I&#125;)$</span>        <span class="hljs-keyword">if</span> noise <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:            noise = torch.randn_like(x0)        <span class="hljs-comment"># Sample $x_t$ for $q(x_t|x_0)$</span>        xt = self.q_sample(x0, t, eps=noise)        <span class="hljs-comment"># Get $\textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(\sqrt&#123;\bar\alpha_t&#125; x_0 + \sqrt&#123;1-\bar\alpha_t&#125;\epsilon, t)$</span>        eps_theta = self.eps_model(xt, t)        <span class="hljs-comment"># MSE loss</span>        <span class="hljs-keyword">return</span> F.mse_loss(noise, eps_theta)</code></pre></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>DALL-E</title>
    <link href="/2022/03/31/DALL-E/"/>
    <url>/2022/03/31/DALL-E/</url>
    
    <content type="html"><![CDATA[<h2 id="dall-e">DALL-E</h2><p>主要由三部分组成，dVAE、transformer、CLIP。</p><p>120亿参数，250m的text-iamge对数据。</p><p>两阶段训练过程：</p><ul><li>训练一个dVAE，作用是将原本<span class="math inline">\(256 \times 256 \times 3\)</span>的RGB图片降为<span class="math inline">\(32 \times 32\)</span>的codebook，每个取值范围为<span class="math inline">\([0, 8192]\)</span>的整数。相当于整体降维了192。避免后续训练transformer出现大内存、计算消耗。</li><li>将一阶段得到的图片的<span class="math inline">\(32 \times 32 = 1024\)</span>token和text的256个token进行联合训练一个transformer。</li></ul><h3 id="dvae">dVAE</h3><p>离散分布的重参数：Gumbel Softmax</p><p><strong>重参数</strong>主要为了处理求期望形式的目标函数，对应于ELBO中的第一项。</p><p><span class="math display">\[L_\theta = E_{z-p_\theta(z)}[f(z)]\]</span></p><p>对应于dVAE中的离散情况，我们可以将其写作：</p><p><span class="math display">\[\sum_z p_\theta(z)f(z)\]</span></p><p>直观上来看，z是离散值，有有限种值，那么可以直接对其进行求和求解。但是通常来讲，z的取值范围过大，这是一个几乎没有可能接受的做法。因此采用采样的方式来对其进行估计，直接进行采样，会丢失梯度，无法进行反传，采用Gumbel Softmax方法。</p><h3 id="transformer">transformer</h3><p>text: 256 token size 16384</p><p>image: 1024 token size 8192</p><h3 id="clip">CLIP</h3><p>rerank结果，挑选topk</p><h2 id="rq-vae">RQ-VAE</h2><h3 id="vq-vae">VQ-VAE</h3><p>codebook C: <span class="math inline">\(\{ (k, e(k)\}_{k \in [K]}\)</span>, K表示codebook的大小, <span class="math inline">\(e(k) \in R^{n_z}\)</span></p><p>输入图片：X, encoder：E, decoder: G,</p><p>给定一个vector <span class="math inline">\(z \in R^{n_z}\)</span>, 使用<span class="math inline">\(Q(z; C)\)</span>来表示<span class="math inline">\(z\)</span>的<span class="math inline">\(VQ\)</span>，其计算也十分简单，为：</p><p><span class="math display">\[ Q(z; C) = argmin_{k \in [K]} ||z-e(k)||_2^2\]</span></p><p>那么对于整张图片<span class="math inline">\(X \in R^{H_o \times W_o \times 3}\)</span>，其在输入编码器后得到</p><p><span class="math display">\[Z = E(X) \in R^{H \times W \times n_z}\]</span></p><p>这里我们使用VQ对Z进行编码，得到</p><p><span class="math display">\[M_{hw} = Q(Z_{HW}; C), M_{hw} \in [K]^{hw}\]</span></p><p>即使用codebook的index来表示图片。之后就可以使用 quantized 特征<span class="math inline">\(\hat{Z}\)</span>来代替原始的feature map Z:</p><p><span class="math display">\[\hat{Z} = e(M_{hw}) \in R^{H \times W \times n_z}\]</span></p><p>之后即可使用<span class="math inline">\(\hat{z}\)</span> 送入G中对X进行重建</p><p><span class="math display">\[\hat{X} = G(\hat{Z}) \in R^{H_o \times W_o \times 3}\]</span></p><p>其中有几个值的大小需要重要理解，HW的大小表示将一个图片encoder后的code大小，其影响后续任务的复杂度，HW越小，复杂度越小。K表示整个codebook的大小，即图片能够选择的离散vector的多少，其越大，我们可以选择的特征越多，那么在计算<span class="math inline">\(Q(z; C)\)</span>时能得到更好的特征近似。</p><p>根据信息失真理论，我们使用<span class="math inline">\(HWlog_2 K\)</span> bits的数据去表示一张图片。</p><h3 id="rq-vae-1">RQ-VAE</h3><p>对于DALL-E来说，使用dVAE将一张<span class="math inline">\(256 \times 256\)</span>的图片重新编码为<span class="math inline">\(32 \times 32\)</span>的一系列分离的vector。而对于后续任务来说，更少的code有利于减少计算复杂度和空间复杂度，因为其和HW的二次成正比。那么减少编码后的HW看起来是一个降低复杂度的很理想的答案。但是如果保持整个codebook的大小不变的话，更少的code意味着会带来更大的重建损失，即code所表示的特征与原图片特征图差别会更大。然而我们如果采用增大codebook的方式来减少这种重建损失，又会带来 <strong>codebook collapse problem</strong>(此处还没有去深入了解)。因此本文提出使用Residual Quantization来解决这件事情。</p><p><strong>解决方法：</strong></p><p>采用循环生成策略，每个特征对应的不再是一个code，而是一个code序列。</p><p>不管是增大HW还是增大K，我们的目标都是在向减少重建误差靠齐。那么我们是否有办法使得codebook中的<span class="math inline">\(e(M)\)</span>vector逼近图像的feature map呢。</p><p>RQ-VAE给出了一个多次逼近的想法，即对于VQ-VAE，我们是在codebook中寻找一个最接近图片feature的vector作为其quantized 特征。而RQ-VAE在寻找到这个特征之后，会计算这个特征与feature的差值，然后在codebook中再寻找一个vector作为差值的近似，按照这种做法进行D次，得到一个深度为D的code。表示如下</p><p><span class="math display">\[RQ(z;C, D) = (k_1, ..., K_D) \in [K]^{D}\]</span></p><p>我们将一个<span class="math inline">\(z \in R^{n_z}\)</span>用D个index表示，其中每个index <span class="math inline">\(k\)</span> 计算如下</p><p><span class="math display">\[k_d = Q(r_{d-1};C)\]</span></p><p><span class="math display">\[r_d = r_{d-1}-e(k_d)\]</span></p><p>我们定义<span class="math inline">\(r_0 = z\)</span>, <span class="math inline">\(\hat{z}^{(d)} = \sum_{i=1}^{d} e(k_i)\)</span> ,那么<span class="math inline">\(\hat{z}^1\)</span>就相当于VQ中的<span class="math inline">\(\hat{z}\)</span>。这种思想的做法非常简单，就是通过多次的逼近误差，来达到更精确逼近<span class="math inline">\(z\)</span>的想法。这种做法不会在没有增加K和HW的情况下，达到了更精确逼近特征的目的。</p><p>对于一个图片<span class="math inline">\(X \in R^{H_o \times W_o \times 3}\)</span>，我们将其送入RQ-VAE，其会得到一个编码后的code <span class="math inline">\(M \in [K]^{H \times W \times D}\)</span>，相比于VQ-VAE多出了一个深度D维，但是这并不影响之后的解码使用到的特征维数，因为这个深度D维所表示的是各阶误差，在使用时并不单独使用。</p><p><span class="math display">\[M_{hw} = RQ(E(X)_{hw}; C, D)\]</span></p><p><span class="math display">\[\hat{Z}^{(d)}_{hw} = \sum_{d&#39;=1}^d e(M_{hwd&#39;})\]</span></p><p>在进行解码时，我们是使用<span class="math inline">\(\hat{Z}^{(D)}\)</span>来作为解码器<span class="math inline">\(G\)</span>的输入，这里<span class="math inline">\(\hat{Z}^{(D)}\)</span>可以理解为拥有最精确估计。</p><p><span class="math display">\[\hat{X} = G(\hat{Z}^{(D)})\]</span></p><p><strong>训练LOSS</strong></p><p>RQ-VAE的loss有两部分组成，一个是图片重建误差loss，另一个是各阶<span class="math inline">\(\hat{Z}^{(D)}\)</span>的commitment loss</p><p><span class="math display">\[L = L_{recon} + \beta L_{commit}\]</span></p><p><span class="math display">\[L_{recon} = ||X-\hat{X}||^2_2\]</span></p><p><span class="math display">\[L_{commit} = \sum_{d=1}^D ||Z-sg(\hat{Z}^{(d)})||^2_2\]</span></p><p>其中<span class="math inline">\(sg(\cdot)\)</span>表示禁止梯度反传。</p><h3 id="rq-transformer">RQ-transformer</h3><figure><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/image-20220330185756506.png" alt="" /><figcaption>image-20220330185756506</figcaption></figure><p>分为空间transformer和深度D的transformer两部分</p><p>空间tansformer将<span class="math inline">\(\hat{Z}^{(d-1)}\)</span>作为输入，来预测下一个值，第一个embedding使用可训练的embedding，并在不同的子任务中使用方式不同，例如在text-condition的任务中，使用text embedding作为头。</p><p><span class="math display">\[u_t = PE_T(t) + \sum_{d=1}^D e(S_{t-1, d}) \, \, for \, t &gt; 1\]</span></p><p>而深度D的transformer略显复杂一些，其输入v相当于各阶层不同精确度的<span class="math inline">\(\hat{Z}^{(d)}\)</span>，而且需要对不同的时间都做。</p><p><span class="math display">\[v_{td} = PE_D(d)+\sum_{d&#39;=1}^{d-1} e(S_{td&#39;}) \, \, for \, d&gt;1\]</span></p><p>和空间基本类似，但特殊的，其第一个输入为当前t的空间transformer输出，即可以把深度D看为一个循环预测的transformer。<span class="math inline">\(d=1, v_{t1} = PE_D(1) + h_t\)</span>.</p><h2 id="clip-gen">CLIP-GEN</h2><p>整体来说网络没什么创新点，感觉就是CLIP VQVAE GPT的组合。主要创新点在于使用CLIP来间接的获取text-image 对，从而实现了使用没有label的数据进行训练的想法。</p><figure><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/image-20220330204854561.png" alt="" /><figcaption>image-20220330204854561</figcaption></figure><ol type="a"><li><p>使用无标签数据预训练一个VQVAE，将图片token化</p></li><li><p>使用CLIP将图片数据映射到一个和text相同的特征空间，利用a预训练好的VQVAE，将图片token化;之后训练一个从embedding到token的自回归transformer，来完成从CLIP特征空间到VQVAE token的映射，从而可以使用VQVAE的decoder完成图片生成</p></li><li><p>测试过程，使用CLIP将text映射到统一特征空间，使用b训练的transformer将embedding转化为token,然后使用decoder生成图片。</p></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>VAE</title>
    <link href="/2022/03/31/VAE/"/>
    <url>/2022/03/31/VAE/</url>
    
    <content type="html"><![CDATA[<h2 id="vae">VAE</h2><p>本篇从VAE开始讲起，主要来分析VAE的作用，限制，以及后来的一些改进模型。主要参考 <a href="https://kexue.fm/">科学空间</a>、<a href="https://panxiaoxie.cn">panxiaoxie</a>.</p><h3 id="ae">AE</h3><p>Auto-Encoder 模型是一种非常常见的学习高维数据的低维表示的方式，我们通常训练一个Auto-Encoder模型来让其自动的学习图像的低维表示。</p><p>但是其只是将一幅图像映射到了隐空间中的一个向量上（一个点），不同的图像映射到不同的隐空间中的点。（这个与VQ-VAE还是不一样，虽然大家都是离散的向量）。其并不具备生成没见过的图像的性质，即如果在隐空间中随便找一个vector，然后使用decoder去解码，大概率是得不到想要的图像的。</p><p>这里<strong>不能进行生成的一个解释</strong>是：</p><p>对于AE模型，由于其encoder和decoder都是神经网络，使用了非线性变化的过程，其隐空间变量和原始空间之间可能并不能找到一个合理的关系，导致随机采样得到的解码结果往往是乱码或十分模糊。</p><h3 id="vae-1">VAE</h3><p>上面说到，AE模型中的每个样本，都会映射到隐空间的一个点上，这导致其在隐空间中随机采样一个点并不能得到好的生成效果。VAE的想法与此不同，其不再将每个样本映射到隐空间的一个点上，而是将每一个样本都映射到一个分布上去，然后再从这个分布上采样一个点，去重建原本的样本，这样就做到了可以在隐空间中采样去生成图像。</p><figure><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/2584918486.png" alt="" /><figcaption>事实上，vae是为每个样本构造专属的正态分布，然后采样来重构</figcaption></figure><p>图像来源<a href="https://kexue.fm/archives/5253">科学空间</a></p><p>生成模型的目标在于找到数据样本的分布，即我们给定一个数据集<span class="math inline">\(X = \{X_1, X_2, ... X_n\}\)</span>, 如果我们能找到一个分布<span class="math inline">\(p(X)\)</span>, 其表示了数据集<span class="math inline">\(X\)</span>的分布，那么我们就可以直接在<span class="math inline">\(p(X)\)</span>中采样，得到所有的数据，包括数据集<span class="math inline">\(X\)</span>中没有出现过的数据。然而这个目标是无法实现的，我们可以通过另一种方式来实现：</p><p><span class="math display">\[p(X) = \sum_m p(m)p(x|m) = \int_zp(z)p(x|z)dz\]</span></p><p>上面，<span class="math inline">\(m \sim p(m), x|m \sim N(\mu^m, \delta^m)\)</span>。经过这样的变化，我们将存在大量失真区域的隐空间，转变为连续的隐空间。这里，VAE的想法就非常自然了，既然AE模型得到的只是隐空间中的一个点，那么VAE直接将其映射到一个正态分布，使得其能够包含整个隐空间。</p><p>我们可以看出来，整个模型中包含：</p><p><span class="math display">\[p(z) \sim N(0, 1), \]</span>先验概率，即假设噪声z的分布服从标准正态分布。</p><p><span class="math display">\[p(x|z)\]</span>， 似然概率，其对应于VAE中的decoder模型</p><p><span class="math display">\[q(z|x)\]</span>，后验分布，对应于VAE中的encoder模型，假设也为正态分布。</p><p>我们从上可以看出，因为我们已经假设p(z)，那么我们只要最大似然就可以很容易的优化<span class="math display">\[p(X)\]</span>，然而由于我们不可能去采样所有的<span class="math inline">\(p(z)\)</span>，因此这种方法不可行。</p><p>那么我们使用<span class="math inline">\(q(z|x)\)</span>来辅助求解<span class="math inline">\(p(x|z)\)</span>。我们的目标在于最大化<span class="math inline">\(log \,p(X)\)</span></p><p>我们可以推导：</p><figure><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/VAE.png" alt="" /><figcaption>[公式]</figcaption></figure><p>右边一项由于KL函数的性质，恒大于0，因此我们找到了<span class="math inline">\(log \, P(x)\)</span>的一个下界：</p><figure><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/ELBO.png" alt="" /><figcaption>[公式]</figcaption></figure><p>我们将其记做<span class="math inline">\(L_b\)</span>，那么原式可以写作：</p><p><span class="math display">\[logP(x) = L_b+KL(q(z|x)||P(z|x))\]</span></p><p>根据公式，<span class="math inline">\(P(x) = \int_zP(z)P(x|z)dz\)</span>，当我们固定了<span class="math inline">\(P(x|z)\)</span>，那么<span class="math inline">\(P(x)\)</span>就是固定的，而此时我们可以通过调整<span class="math inline">\(q(z|x)\)</span>即编码器，来使得KL散度项趋近于零。也就是说，L_b项可以代表我们想要求的<span class="math inline">\(logP\)</span>。</p><p>那么我们的优化目标就可以变为优化<span class="math inline">\(L_b\)</span>。</p><figure><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/ELBO2.png" alt="" /><figcaption>[公式]</figcaption></figure><p>对于第一项，由于我们有假设<span class="math inline">\(q \sim N(\mu, \delta^2), P(z) \sim N(0, 1)\)</span>，可以根据KL散度公式进行展开，推导过程借用：</p><figure><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/KL.png" alt="" /><figcaption>img</figcaption></figure><p>对于第二项，我们可以将其表示为</p><p><span class="math display">\[\int_zq(z|x)logP(x|z)dz = E_{q(z|x)}[logP(x|z)]\]</span></p><p>可以将其理解为AE的损失函数。</p><p>实际上我们从另一个角度理解这个损失函数，可以更具体一些。即我们一个朴素的思想还是，使得我们的重构误差最小，即上式中的第二项。但是VAE为什么还要有其他的loss呢？直观的，我们如果只包含一个重构loss，那么由于encoder得出的是一个均值和方差，为了让loss更小，模型学习的方法肯定会让方差等于0，也就是失去了随机噪声，VAE就会退化为AE模型。那么我们另一个直观的想法，既然后验分布需要一定的噪声，那么我们就强迫其向标准正态靠近，因此可以加一个loss来衡量它和标准正态的距离，这个衡量函数就是KL散度。</p><p>代码实现：</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">VariationalEncoder</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, latent_dims</span>):</span>        <span class="hljs-built_in">super</span>(VariationalEncoder, self).__init__()        self.linear1 = nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">512</span>)        self.linear2 = nn.Linear(<span class="hljs-number">512</span>, latent_dims)        self.linear3 = nn.Linear(<span class="hljs-number">512</span>, latent_dims)                self.kl = <span class="hljs-number">0</span>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        x = torch.flatten(x, start_dim=<span class="hljs-number">1</span>)        x = F.relu(self.linear1(x))        mu =  self.linear2(x)        sigma = torch.exp(self.linear3(x))                z = mu + sigma*torch.randn_like(sigma)        self.kl = <span class="hljs-number">0.5</span>*(sigma**<span class="hljs-number">2</span> + mu**<span class="hljs-number">2</span> - torch.log(sigma) - <span class="hljs-number">1</span>).<span class="hljs-built_in">sum</span>()        <span class="hljs-keyword">return</span> z<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Decoder</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, latent_dims</span>):</span>        <span class="hljs-built_in">super</span>(Decoder, self).__init__()        self.linear1 = nn.Linear(latent_dims, <span class="hljs-number">512</span>)        self.linear2 = nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">784</span>)            <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, z</span>):</span>        x_hat = F.relu(self.linear1(z))        x_hat = torch.sigmoid(self.linear2(x_hat))        <span class="hljs-keyword">return</span> x_hat.reshape((<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>))      <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">VariationalAutoencoder</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, latent_dims</span>):</span>        <span class="hljs-built_in">super</span>(VariationalAutoencoder, self).__init__()        self.encoder = VariationalEncoder(latent_dims)        self.decoder = Decoder(latent_dims)        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        z = self.encoder(x)        <span class="hljs-keyword">return</span> self.decoder(z)</code></pre><h3 id="vqvae">VQVAE</h3><p>不同于VAE，其不再将图片编码到一个连续的空间，而是像AE一样的离散空间。其过程为</p><p>codebook C: <span class="math inline">\(\{ (k, e(k)\}_{k \in [K]}\)</span>, K表示codebook的大小, <span class="math inline">\(e(k) \in R^{n_z}\)</span></p><p>输入图片：X, encoder：E, decoder: G,</p><p>给定一个vector <span class="math inline">\(z \in R^{n_z}\)</span>, 使用<span class="math inline">\(Q(z; C)\)</span>来表示<span class="math inline">\(z\)</span>的<span class="math inline">\(VQ\)</span>，其计算也十分简单，为：</p><p><span class="math display">\[ Q(z; C) = argmin_{k \in [K]} ||z-e(k)||_2^2\]</span></p><p>那么对于整张图片<span class="math inline">\(X \in R^{H_o \times W_o \times 3}\)</span>，其在输入编码器后得到</p><p><span class="math display">\[Z = E(X) \in R^{H \times W \times n_z}\]</span></p><p>这里我们使用VQ对Z进行编码，得到</p><p><span class="math display">\[M_{hw} = Q(Z_{HW}; C), M_{hw} \in [K]^{hw}\]</span></p><p>即使用codebook的index来表示图片。之后就可以使用 quantized 特征<span class="math inline">\(\hat{Z}\)</span>来代替原始的feature map Z:</p><p><span class="math display">\[\hat{Z} = e(M_{hw}) \in R^{H \times W \times n_z}\]</span></p><p>之后即可使用<span class="math inline">\(\hat{z}\)</span> 送入G中对X进行重建</p><p><span class="math display">\[\hat{X} = G(\hat{Z}) \in R^{H_o \times W_o \times 3}\]</span></p><p><strong>梯度反传</strong></p><p>我们可以看到，在前向求<span class="math inline">\(\hat{Z}\)</span>时，用到了<span class="math inline">\(arg min\)</span>操作，这个操作本身是没有梯度的，如果我们在优化时，使用着一个loss：</p><p><span class="math display">\[||x-decoder(\hat{z})||^2_2\]</span></p><p>其梯度不会更新encoder，梯度在<span class="math inline">\(argmin\)</span>那里就停止了。这里VQVAE使用了Straight-Through Estimator方法，其思想十分简单，就是在前向传播时使用自己想要得变量进行计算，而在反向chanson时，使用自己为其设计的梯度。在这里，VQVAE就是用了<span class="math inline">\(z\)</span>的梯度来代替<span class="math inline">\(\hat{z}\)</span>：</p><p><span class="math display">\[||x-decoder(z + sg(\hat{z}-z))||^2_2\]</span></p><p>这样在前向计算时，使用<span class="math inline">\(\hat{z}\)</span>而在反向传播时使用<span class="math inline">\(z\)</span>。从而可以对encoder进行优化。</p><p>代码实现</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Encoder</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, latent_dims, pic_channels=<span class="hljs-number">1</span></span>):</span>        <span class="hljs-built_in">super</span>(Encoder, self).__init__()        self.conv1 = nn.Conv2d(in_channels=pic_channels, out_channels=latent_dims//<span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">4</span>)        self.conv2 = nn.Conv2d(in_channels=latent_dims//<span class="hljs-number">2</span>, out_channels=latent_dims, kernel_size=<span class="hljs-number">4</span>)    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        x = self.conv1(x)        x = F.relu(x)        x = self.conv2(x)        <span class="hljs-comment">#print(x)</span>        <span class="hljs-keyword">return</span> x      <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Decoder</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, latent_dims, pic_channels=<span class="hljs-number">1</span></span>):</span>        <span class="hljs-built_in">super</span>(Decoder, self).__init__()        self.conv_trans1 = nn.ConvTranspose2d(          in_channels=latent_dims, out_channels=latent_dims//<span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">4</span>)        self.conv_trans2 = nn.ConvTranspose2d(          in_channels=latent_dims//<span class="hljs-number">2</span>, out_channels=pic_channels, kernel_size=<span class="hljs-number">4</span>)    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        x = self.conv_trans1(x)        x = F.relu(x)        x = self.conv_trans2(x)        <span class="hljs-keyword">return</span> x       <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">VectorQuantizer</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, latent_dims, num_codes=<span class="hljs-number">32</span>, beta=<span class="hljs-number">0.25</span></span>):</span>        <span class="hljs-built_in">super</span>(VectorQuantizer, self).__init__()        self.K = num_codes        self.D = latent_dims        self.beta = beta        self.codebook = nn.Embedding(self.K, self.D)        self.codebook.weight.data.uniform_(<span class="hljs-number">-1</span> / self.K, <span class="hljs-number">1</span> / self.K)        self.vq_loss = <span class="hljs-number">0</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, latents</span>):</span>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><span class="hljs-string">         latents: (batch, dim, height, width)</span><span class="hljs-string">         codebook: (K, dim)</span><span class="hljs-string">        &#x27;&#x27;&#x27;</span>        <span class="hljs-comment"># convert latents from BCHW -&gt; BHWC</span>        latents = latents.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>).contiguous() <span class="hljs-comment"># (B, H, W, dim)</span>        latents_shape = latents.shape                <span class="hljs-comment"># Flatten latent</span>        flat_latent = latents.view(<span class="hljs-number">-1</span>, self.D) <span class="hljs-comment"># (BHW, dim)</span>        <span class="hljs-comment"># Compute L2 distance between latents and codes in codebook</span>        dist = (flat_latent.unsqueeze(<span class="hljs-number">1</span>) - self.codebook.weight.unsqueeze(<span class="hljs-number">0</span>)) ** <span class="hljs-number">2</span> <span class="hljs-comment"># (BHW, 1, dim) - (1, K, dim) -&gt; (BHW, K, dim)</span>        dist = dist.<span class="hljs-built_in">sum</span>(<span class="hljs-number">-1</span>) <span class="hljs-comment"># (BHW, K)</span>        <span class="hljs-comment"># Get the code index that has the min distance</span>        nearest_idxs = torch.argmin(dist, dim=<span class="hljs-number">1</span>).unsqueeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># (BHW, 1)</span>        <span class="hljs-comment"># Convert to one-hot</span>        nearest_one_hot = torch.zeros(nearest_idxs.size(<span class="hljs-number">0</span>), self.K, device=latents.device) <span class="hljs-comment"># (BHW, K)</span>        nearest_one_hot.scatter_(<span class="hljs-number">1</span>, nearest_idxs, <span class="hljs-number">1</span>)  <span class="hljs-comment"># .scatter(dim,index,src)</span>        <span class="hljs-comment"># Quantize the latents</span>        quantized_latents = torch.matmul(nearest_one_hot, self.codebook.weight).view(latents_shape) <span class="hljs-comment"># (BHW, K) * (K, dim) = (BHW, dim) -&gt; (B, H, W, dim)</span>        <span class="hljs-comment"># Compute the VQ Losses</span>        commitment_loss = F.mse_loss(quantized_latents.detach(), latents)        codebook_loss = F.mse_loss(quantized_latents, latents.detach())        self.vq_loss = commitment_loss * self.beta + codebook_loss        <span class="hljs-comment"># convert quantized from BHWC -&gt; BCHW</span>        quantized_latents = latents + (quantized_latents - latents).detach()<span class="hljs-keyword">return</span> quantized_latents.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous()      <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">VQVariationalAutoencoder</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, latent_dims, ema=<span class="hljs-literal">True</span></span>):</span>        <span class="hljs-built_in">super</span>(VQVariationalAutoencoder, self).__init__()        self.encoder = Encoder(latent_dims)        <span class="hljs-keyword">if</span> ema:          self.vector_quantizer = VectorQuantizerEMA(latent_dims)        <span class="hljs-keyword">else</span>:          self.vector_quantizer = VectorQuantizer(latent_dims)        self.decoder = Decoder(latent_dims)        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        z_e = self.encoder(x)        z_q = self.vector_quantizer(z_e) <span class="hljs-comment"># (batch, dim, 22, 22)</span>        <span class="hljs-keyword">return</span> self.decoder(z_q)</code></pre><p>其中在74行可以看出我们VQVAE设计的梯度。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>学习记录</title>
    <link href="/2021/07/06/transformer/"/>
    <url>/2021/07/06/transformer/</url>
    
    <content type="html"><![CDATA[<h3 id="warm-up">warm up</h3><p>warm up 是一种治标之法，warm up能解决模型初期难以收敛的问题，但这种解决方式并不根本。因为模型前期难以收敛意味着模型会受到较大的扰动，即一点梯度的变化会影响整个模型的抖动。我们应该做的是修改模型的结构来解决这个问题而不是降低学习率。可以考虑是否是层数太多，一般来说，层数多的话，需要降低梯度的大小，否则会导致不收敛。</p><h3 id="增量爆炸">增量爆炸</h3><p>模型越深，对输出的扰动就越大。</p><h3 id="transformer-的pre-norm-和post-norm">transformer 的Pre Norm 和Post Norm</h3><p>一般来说，Pre Norm会比Post Norm更容易训练一些，但是Post Norm的最终效果往往更好。清华的一篇text-2-img文章CogView中，提出了一个三明治型的Norm方式，即同时使用Pre Norm 和 Post Norm。</p>]]></content>
    
    
    
    <tags>
      
      <tag>transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>fast-slow-pointer</title>
    <link href="/2020/11/08/fast-slow-pointer/"/>
    <url>/2020/11/08/fast-slow-pointer/</url>
    
    <content type="html"><![CDATA[<p>(image/)</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>利用github搭建自己的博客</title>
    <link href="/2020/11/08/hello-world/"/>
    <url>/2020/11/08/hello-world/</url>
    
    <content type="html"><![CDATA[<p>下面记录一下我是如何利用GitHub来搭建自己的博客。</p><h2 id="准备工作">1. 准备工作</h2><ul><li>安装Node.js</li></ul><p>官网为：https://nodejs.org/zh-cn/ 建议下载安装长期支持版。安装后win+r打开终端，测试npm命令行工具能不能�? <pre><code class="hljs coffeescript"><span class="hljs-built_in">npm</span> -v</code></pre> 注：若已安装过Node.js，可以查看一下版本号，确保和下面要安装的Hexo兼容 <pre><code class="hljs crmsh"><span class="hljs-comment"># 查看Node.js版本</span><span class="hljs-keyword">node</span> <span class="hljs-title">-v</span></code></pre> <img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/20210630162300.png" alt="20210630162300" /></p><ul><li>安装git</li></ul><p>这个相信大家应该都有，没有的话去 https://git-scm.com/download/win 下载安装</p><ul><li>安装Hexo</li></ul><p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p><pre><code class="hljs avrasm"><span class="hljs-meta"># 安装hexo</span>npm install -g hexo-<span class="hljs-keyword">cli</span></code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>教程</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
