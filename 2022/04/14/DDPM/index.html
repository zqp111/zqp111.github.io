

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="主要有算法相关，计算机视觉相关，动作识别。">
  <meta name="author" content="zqp">
  <meta name="keywords" content="python，pytorch，计算机视觉，动作识别">
  <title>Diffusion model - 学习随笔</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.5.3/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.1.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"copy_btn":true,"image_zoom":{"enable":true},"lazyload":{"enable":true,"onlypost":false},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.2.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>随笔记录</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Diffusion model">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-04-14 10:02" pubdate>
        2022年4月14日 上午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.7k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      62
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Diffusion model</h1>
            
            <div class="markdown-body">
              <h2 id="diffusion-model">Diffusion model</h2>
<p>本篇主要总结diffusion model的学习, 主要设计DDPM这篇文章中所提出的算法.</p>
<h3 id="生成模型">生成模型</h3>
<p>生成模型的的主要目标在于找到一个概率分布<span class="math inline">\(p(x)\)</span>,其能表示数据集的所有分布.包含当前数据集中已有的和当前数据集同一分布的其他数据.这样,我们就可以通过采样<span class="math inline">\(p(x)\)</span>来生成新的数据.</p>
<h3 id="基于得分模型">基于得分模型</h3>
<p>一个朴素的想法是,</p>
<p><span class="math display">\[\begin{equation}
p_\theta(x) = \frac{e^{-f_\theta(x)}}{Z_\theta}
\end{equation}\]</span></p>
<p>其中<span class="math inline">\(Z_\theta\)</span>是一个归一化常量,使得<span class="math inline">\(p_\theta\)</span>为满足<span class="math inline">\(\int p_\theta (x) dx = 1\)</span>的概率密度函数.但是这里存在一个问题,<span class="math inline">\(Z_{\theta}\)</span>的取值取决于<span class="math inline">\(f_\theta (x)\)</span>, 然而计算<span class="math inline">\(Z_{\theta}\)</span>通常情况下是非常困难的.那么我们可以换另一种方式, 我们可以对概率密度函数的梯度进行建模.</p>
<p><span class="math display">\[\begin{equation}
s_\theta (x) = \nabla_x log \, p_\theta(x) = \nabla_x f_\theta (x) - \nabla_x log \, Z_{\theta} = -\nabla_x f_\theta (x)
\end{equation}\]</span></p>
<p>这样,我们可以不用再考虑<span class="math inline">\(\theta\)</span> 带来的归一化计算问题.</p>
<p>在采样生成新的样本的时候,我们可以通过 langevin dynamics采样. langevin dynamics 仅使用<span class="math inline">\(\nabla_x log \, p(x)\)</span>来从<span class="math inline">\(p(x)\)</span>分布中采样.其过程为:</p>
<p><span class="math display">\[\begin{equation}
x_{i+1} \leftarrow x_i + \epsilon \nabla_x log \, p(x) + \sqrt{2 \epsilon } z_i 
\end{equation}\]</span></p>
<p>其中<span class="math inline">\(z_i \sim N(0,1)\)</span>, <span class="math inline">\(i\rightarrow \infty, \epsilon \rightarrow 0\)</span>,我们得到一个<span class="math inline">\(p(x)\)</span>的采样,在这里,我们可以使用<span class="math inline">\(s_\theta(x)\)</span>来代替<span class="math inline">\(\nabla_x log \, p(x)\)</span>,从而进行采样.</p>
<h3 id="缺陷">缺陷</h3>
<p><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/smld.jpg" srcset="/img/loading.gif" alt="img" style="zoom:20%;" /></p>
<p>这里看似很美好,但存在着一个比较大的问题.在所给数据集的低密度区域,分数函数的估计是不准确的,这会导致很难生成高质量的样本.</p>
<h3 id="解决方式">解决方式</h3>
<p>既然问题出在低密度区域的估计上,那么我们是不是可以人为的填充低密度区域,使其在所有地方都估计准确呢.这里就可以在我们的样本上叠加足够的噪声,当噪声的幅值足够大时,数据空间中将不会再有低密度区域.又引出另一个问题,如何控制噪声的大小呢.当噪声较小时,不能达到我们想要覆盖整个空间的效果, 而当噪声过大时,又会破坏原始数据的分布.</p>
<p>使用一系列不同尺度的噪声进行扰动, 可以综合解决以上两个问题.这里的解决方式,实际上就已经引出我们要介绍的模型,<strong>DDPM</strong>.</p>
<h3 id="ddpm">DDPM</h3>
<ol type="1">
<li><p><strong>前向过程</strong></p>
<p>前向过程就是我们节所说的,对样本添加一系列不同尺度的噪声.对于一个数据<span class="math inline">\(x_0 \sim q(x)\)</span>,我们在<span class="math inline">\(T\)</span>步内对其添加一系列高斯噪声,得到一个加噪序列<span class="math inline">\(x_1, ... x_T\)</span>.每步添加的噪声大小,由超参数<span class="math inline">\(\beta_t \in (0,1)\)</span>控制.</p>
<p><span class="math display">\[\begin{equation}
q(x_t|x_{t-1}) = N(x_t;\sqrt{1-\beta_t}x_{t-1}, \beta_t I)
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
q(x_{1:T}|x_0) = \prod_{t=1}^{T}{q(x_t|x_{t-1})}
\end{equation}\]</span></p>
<p>加噪数据<span class="math inline">\(x_t\)</span>随着<span class="math inline">\(t\)</span>的增加,逐渐变为一个高斯噪声.</p>
<p><img src="https://cdn.jsdelivr.net/gh/zqp111/pic_bed/image/DDPM.png" srcset="/img/loading.gif" alt="img" style="zoom:15%;" /></p>
<p>对于上述过程,我们使用重参数技巧,可以很好的进行合并,使得可以一步计算出t步的加噪图像.</p>
<blockquote>
<h3 id="重参数技巧">重参数技巧</h3>
<p>这里我们回顾一下重参数技巧,他在VAE中也有用到,用来从一个分布中采样,同时保持梯度.</p>
<p>假设我们需要采样<span class="math inline">\(q(x_t|x_{t-1}) = N(x_t;\sqrt{1-\beta_t}x_{t-1}, \beta_t I)\)</span>,我们可以取一个变量<span class="math inline">\(z \sim N(0,1)\)</span>,根据高斯分布的特性,不同高斯分布数据之间转移关系为<span class="math inline">\(\mu + \sigma z\)</span>, 可以得到</p>
<p><span class="math display">\[x_t = \sqrt{1-\beta_t}x_{t-1} + \sqrt{\beta_t} z \]</span></p>
</blockquote>
<p><span class="math display">\[\begin{equation}
\begin{aligned} 
x_t &amp;= \sqrt{\alpha_t}x_{t-1} + \sqrt{1 - \alpha_t}z_{t-1} &amp; \text{ ;where } z_{t-1}, z_{t-2}, \dots \sim {N}({0}, {I}) \\ 
&amp;= \color{blue}{\sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_{t-1}}z_{t-2}) + \sqrt{1 - \alpha_t}z_{t-1}}\\ 
&amp;= \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \bar z_{t-2} &amp; \text{ ;where } \bar z_{t-2} \text{ merges two Gaussians (*).} \\ &amp;= \dots \\ 
&amp;= \sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}z \\ 
\end{aligned}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
q(x_t \vert x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t){I}) 
\end{equation}\]</span></p>
<p>其中<span class="math inline">\(\alpha_t = 1- \beta_t, \bar{\alpha_t} = \prod_{i=1}^{T} \alpha_i\)</span></p></li>
<li><p><strong>反向过程</strong></p>
<p>正向过程添加噪声,那么我们只要在反向时,去除噪声,就能得到原始数据.我们利用<span class="math inline">\(q(x_{t-1}|x_t)\)</span>从高斯噪声<span class="math inline">\(x_T\)</span>,经过不断去噪,最终能重建真实样本.但是,我们无法直接得到<span class="math inline">\(q(x_{t-1}|x_t)\)</span>. 类似于VAE中的encoder,我们学习一个模型<span class="math inline">\(p_{\theta}\)</span>来估计,也就是 <span class="math inline">\(q(x_{t-1}|x_t) \sim p_θ(x_{t-1}|x_t)\)</span>.</p>
<p>在<span class="math inline">\(\beta_t\)</span>很小的情况下, <span class="math inline">\(p_θ(x_{t-1}|x_t)\)</span>依然为高斯分布,即有:</p>
<p><span class="math display">\[\begin{equation}
p_θ(x_{t-1}|x_t) = N(x_{t-1}; \mu_{\theta}(x_t,t), \sum_{\theta}(x_t, t))
\end{equation}\]</span></p>
<p>在条件<span class="math inline">\(x_0\)</span>时,有:</p>
<p><span class="math display">\[\begin{equation}
q(x_{t-1}|x_t, x_0) = N(x_{t-1};\tilde{\mu}(x_t,x_0),\tilde{\beta_t}I)
\end{equation}\]</span></p>
<p>我们利用贝叶斯公式,得到:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
q(x_{t-1}|x_t, x_0) &amp;= q(x_t|x_{t-1}, x_0)\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} \\
             &amp;=N(x_t; \sqrt(\alpha_t) x_{t-1}, \beta_t) \frac{N(x_{t-1}; \sqrt(\bar{\alpha_{t-1})} x_0, (1-\bar{\alpha_{t-1}}))}{N(x_t; \sqrt(\bar{\alpha_t}) x_0, (1-\bar{\alpha_{t}}))} \\
             &amp;\propto \exp \Big(-\frac{1}{2} \big(\frac{(\mathbf x_t - \sqrt{\alpha_t} \mathbf x_{t-1})^2}{\beta_t} + \frac{(\mathbf x_{t-1} - \sqrt{\bar \alpha_{t-1}} \mathbf x_0)^2}{1-\bar \alpha_{t-1}} - \frac{(\mathbf x_t - \sqrt{\bar \alpha_t} \mathbf x_0)^2}{1-\bar \alpha_t} \big) \Big) \\ 
             &amp;= \exp\Big( -\frac{1}{2} \big( \color{red}{(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar \alpha_{t-1}})} \mathbf x_{t-1}^2 - \color{blue}{(\frac{2\sqrt{\alpha_t}}{\beta_t} \mathbf x_t + \frac{2\sqrt{\bar \alpha_t}}{1 - \bar \alpha_t} \mathbf x_0)} \mathbf x_{t-1} + C(\mathbf x_t, \mathbf x_0) \big) \Big)  
\end{aligned}
\end{equation}\]</span></p>
<p>其中<span class="math inline">\(C(x_t, x_0)\)</span>不涉及<span class="math inline">\(x_{t-1}\)</span>,可以认为对标准高斯分布的均值方差无影响,可以省略.根据标准的高斯密度函数,我们可以得到其中<span class="math inline">\(\tilde{\mu}(x_t,x_0),\tilde{\beta_t}\)</span>的表达式</p>
<p><span class="math display">\[\begin{equation} 
\tilde{\mu}(\mathbf x_t,\mathbf x_0) = 1/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar \alpha_{t-1}}) = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_{t}} \cdot \beta_t  
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\tilde \mu_t (\mathbf x_t, \mathbf x_0) = (\frac{\sqrt{\alpha_t}}{\beta_t} \mathbf x_t + \frac{\sqrt{\bar \alpha_t}}{1 - \bar \alpha_t} \mathbf x_0)/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar \alpha_{t-1}}) = \frac{\sqrt{\alpha_t}(1 - \bar \alpha_{t-1})}{1 - \bar \alpha_t} \mathbf x_t + \frac{\sqrt{\bar \alpha_{t-1}}\beta_t}{1 - \bar \alpha_t} \mathbf x_0 
\end{equation}\]</span></p>
<p>我们根据前向过程的计算公式,可以知道<span class="math inline">\(\mathbf{x}_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\mathbf{z }_t)\)</span>.将其带入上式中,可以得到:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\tilde{\boldsymbol{\mu}}_t
&amp;= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\mathbf{z}_t) \\
&amp;= \color{cyan}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_t \Big)}
\end{aligned}
\end{equation}\]</span></p>
<p>再次回顾一下,我们最初的想法是拿<span class="math inline">\(p_θ(x_{t-1}|x_t)\)</span> 估计<span class="math inline">\(q(x_{t-1}|x_t)\)</span>, 推导后我们可以看到,我们可以仅仅估计<span class="math inline">\(z_t\)</span>就能达到这个目的.(因为其他的都是常量).实际上,下节的Loss推导过程中,最后也得出来这样计算loss较为简单.</p></li>
<li><p><strong>Loss计算</strong></p>
<p>我们的目标是最大化似然函数: <span class="math display">\[\begin{equation}
\begin{aligned}
-\log p_\theta(\mathbf{x}_0) &amp;\leq - \log p_\theta(\mathbf{x}_0) + D_\text{KL}(q(\mathbf{x}_{1:T}\vert\mathbf{x}_0) \| p_\theta(\mathbf{x}_{1:T}\vert\mathbf{x}_0) ) \\
-&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_{\mathbf{x}_{1:T}\sim q(\mathbf{x}_{1:T} \vert \mathbf{x}_0)} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T}) / p_\theta(\mathbf{x}_0)} \Big] \\
&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_q \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} + \log p_\theta(\mathbf{x}_0) \Big] \\
&amp;= \mathbb{E}_q \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\
\text{Let }L_\text{VLB} 
&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \geq - \mathbb{E}_{q(\mathbf{x}_0)} \log p_\theta(\mathbf{x}_0)
\end{aligned}
\end{equation}\]</span></p>
<p>为将上述方程的每项都转变为可计算的,可以将其重写为几个KL散度的组合.</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
L_\text{VLB} 
&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\
&amp;= \mathbb{E}_q \Big[ \log\frac{\prod_{t=1}^T q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{ p_\theta(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t) } \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=1}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \Big( \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)}\cdot \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1}\vert\mathbf{x}_0)} \Big) + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1} \vert \mathbf{x}_0)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{q(\mathbf{x}_1 \vert \mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big]\\
&amp;= \mathbb{E}_q \Big[ \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_T)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} - \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1) \Big] \\
&amp;= \mathbb{E}_q [\underbrace{D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T))}_{L_T} + \sum_{t=2}^T \underbrace{D_\text{KL}(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t))}_{L_{t-1}} \underbrace{- \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)}_{L_0} ]
\end{aligned}
\end{equation}
\]</span> 其中<span class="math inline">\(L_T\)</span>为常数项,因为<span class="math inline">\(q(x_T|x_0)\)</span>没有参数.</p>
<p>对于<span class="math inline">\(L_t\)</span>项:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
L_t 
&amp;= \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \Big[\frac{1}{2 \| \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t) \|^2_2} \| \color{blue}{\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0)} - \color{green}{\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)} \|^2 \Big] \\
&amp;= \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \Big[\frac{1}{2  \|\boldsymbol{\Sigma}_\theta \|^2_2} \| \color{blue}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_t \Big)} - \color{green}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\mathbf{z}}_\theta(\mathbf{x}_t, t) \Big)} \|^2 \Big] \\
&amp;= \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \Big[\frac{ \beta_t^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \| \boldsymbol{\Sigma}_\theta \|^2_2} \|\mathbf{z}_t - \mathbf{z}_\theta(\mathbf{x}_t, t)\|^2 \Big] \\
&amp;= \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \Big[\frac{ \beta_t^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \| \boldsymbol{\Sigma}_\theta \|^2_2} \|\mathbf{z}_t - \mathbf{z}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\mathbf{z}_t, t)\|^2 \Big] 
\end{aligned}
\end{equation}\]</span></p>
<p>忽略其加权项,得到简化的loss <span class="math display">\[\begin{equation}
L_t^\text{simple} = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}_t} \Big[\|\mathbf{z}_t - \mathbf{z}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\mathbf{z}_t, t)\|^2 \Big]
\end{equation}\]</span></p></li>
<li><p><strong>直观理解</strong></p>
<p>直观上,我们可以把<span class="math inline">\(p_θ(x_{t-1}|x_t)\)</span> 理解为利用一个模型根据加噪图像去预测其噪声,然后我们计算预测出的噪声和原本加入的噪声的mse loss.</p></li>
<li><p><strong>代码</strong></p>
<pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DenoiseDiffusion</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">    ## Denoise Diffusion</span>
<span class="hljs-string">    &quot;&quot;&quot;</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, eps_model: nn.Module, n_steps: <span class="hljs-built_in">int</span>, device: torch.device</span>):</span>
        <span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">        * `eps_model` is $\textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(x_t, t)$ model</span>
<span class="hljs-string">        * `n_steps` is $t$</span>
<span class="hljs-string">        * `device` is the device to place constants on</span>
<span class="hljs-string">        &quot;&quot;&quot;</span>
        <span class="hljs-built_in">super</span>().__init__()
        self.eps_model = eps_model

        <span class="hljs-comment"># Create $\beta_1, \dots, \beta_T$ linearly increasing variance schedule</span>
        self.beta = torch.linspace(<span class="hljs-number">0.0001</span>, <span class="hljs-number">0.02</span>, n_steps).to(device)

        <span class="hljs-comment"># $\alpha_t = 1 - \beta_t$</span>
        self.alpha = <span class="hljs-number">1.</span> - self.beta
        <span class="hljs-comment"># $\bar\alpha_t = \prod_&#123;s=1&#125;^t \alpha_s$</span>
        self.alpha_bar = torch.cumprod(self.alpha, dim=<span class="hljs-number">0</span>)
        <span class="hljs-comment"># $T$</span>
        self.n_steps = n_steps
        <span class="hljs-comment"># $\sigma^2 = \beta$</span>
        self.sigma2 = self.beta

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">q_xt_x0</span>(<span class="hljs-params">self, x0: torch.Tensor, t: torch.Tensor</span>) -&gt; Tuple[torch.Tensor, torch.Tensor]:</span>
        <span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">        #### Get $q(x_t|x_0)$ distribution</span>
<span class="hljs-string">        \begin&#123;align&#125;</span>
<span class="hljs-string">        q(x_t|x_0) &amp;= \mathcal&#123;N&#125; \Big(x_t; \sqrt&#123;\bar\alpha_t&#125; x_0, (1-\bar\alpha_t) \mathbf&#123;I&#125; \Big)</span>
<span class="hljs-string">        \end&#123;align&#125;</span>
<span class="hljs-string">        &quot;&quot;&quot;</span>

        <span class="hljs-comment"># [gather](utils.html) $\alpha_t$ and compute $\sqrt&#123;\bar\alpha_t&#125; x_0$</span>
        mean = gather(self.alpha_bar, t) ** <span class="hljs-number">0.5</span> * x0
        <span class="hljs-comment"># $(1-\bar\alpha_t) \mathbf&#123;I&#125;$</span>
        var = <span class="hljs-number">1</span> - gather(self.alpha_bar, t)
        <span class="hljs-comment">#</span>
        <span class="hljs-keyword">return</span> mean, var

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">q_sample</span>(<span class="hljs-params">self, x0: torch.Tensor, t: torch.Tensor, eps: Optional[torch.Tensor] = <span class="hljs-literal">None</span></span>):</span>
        <span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">        #### Sample from $q(x_t|x_0)$</span>
<span class="hljs-string">        \begin&#123;align&#125;</span>
<span class="hljs-string">        q(x_t|x_0) &amp;= \mathcal&#123;N&#125; \Big(x_t; \sqrt&#123;\bar\alpha_t&#125; x_0, (1-\bar\alpha_t) \mathbf&#123;I&#125; \Big)</span>
<span class="hljs-string">        \end&#123;align&#125;</span>
<span class="hljs-string">        &quot;&quot;&quot;</span>

        <span class="hljs-comment"># $\epsilon \sim \mathcal&#123;N&#125;(\mathbf&#123;0&#125;, \mathbf&#123;I&#125;)$</span>
        <span class="hljs-keyword">if</span> eps <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
            eps = torch.randn_like(x0)

        <span class="hljs-comment"># get $q(x_t|x_0)$</span>
        mean, var = self.q_xt_x0(x0, t)
        <span class="hljs-comment"># Sample from $q(x_t|x_0)$</span>
        <span class="hljs-keyword">return</span> mean + (var ** <span class="hljs-number">0.5</span>) * eps

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">p_sample</span>(<span class="hljs-params">self, xt: torch.Tensor, t: torch.Tensor</span>):</span>
        <span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">        #### Sample from $\textcolor&#123;cyan&#125;&#123;p_\theta&#125;(x_&#123;t-1&#125;|x_t)$</span>
<span class="hljs-string">        \begin&#123;align&#125;</span>
<span class="hljs-string">        \textcolor&#123;cyan&#125;&#123;p_\theta&#125;(x_&#123;t-1&#125; | x_t) &amp;= \mathcal&#123;N&#125;\big(x_&#123;t-1&#125;;</span>
<span class="hljs-string">        \textcolor&#123;cyan&#125;&#123;\mu_\theta&#125;(x_t, t), \sigma_t^2 \mathbf&#123;I&#125; \big) \\</span>
<span class="hljs-string">        \textcolor&#123;cyan&#125;&#123;\mu_\theta&#125;(x_t, t)</span>
<span class="hljs-string">          &amp;= \frac&#123;1&#125;&#123;\sqrt&#123;\alpha_t&#125;&#125; \Big(x_t -</span>
<span class="hljs-string">            \frac&#123;\beta_t&#125;&#123;\sqrt&#123;1-\bar\alpha_t&#125;&#125;\textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(x_t, t) \Big)</span>
<span class="hljs-string">        \end&#123;align&#125;</span>
<span class="hljs-string">        &quot;&quot;&quot;</span>

        <span class="hljs-comment"># $\textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(x_t, t)$</span>
        eps_theta = self.eps_model(xt, t)
        <span class="hljs-comment"># [gather](utils.html) $\bar\alpha_t$</span>
        alpha_bar = gather(self.alpha_bar, t)
        <span class="hljs-comment"># $\alpha_t$</span>
        alpha = gather(self.alpha, t)
        <span class="hljs-comment"># $\frac&#123;\beta&#125;&#123;\sqrt&#123;1-\bar\alpha_t&#125;&#125;$</span>
        eps_coef = (<span class="hljs-number">1</span> - alpha) / (<span class="hljs-number">1</span> - alpha_bar) ** <span class="hljs-number">.5</span>
        <span class="hljs-comment"># $$\frac&#123;1&#125;&#123;\sqrt&#123;\alpha_t&#125;&#125; \Big(x_t -</span>
        <span class="hljs-comment">#      \frac&#123;\beta_t&#125;&#123;\sqrt&#123;1-\bar\alpha_t&#125;&#125;\textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(x_t, t) \Big)$$</span>
        mean = <span class="hljs-number">1</span> / (alpha ** <span class="hljs-number">0.5</span>) * (xt - eps_coef * eps_theta)
        <span class="hljs-comment"># $\sigma^2$</span>
        var = gather(self.sigma2, t)

        <span class="hljs-comment"># $\epsilon \sim \mathcal&#123;N&#125;(\mathbf&#123;0&#125;, \mathbf&#123;I&#125;)$</span>
        eps = torch.randn(xt.shape, device=xt.device)
        <span class="hljs-comment"># Sample</span>
        <span class="hljs-keyword">return</span> mean + (var ** <span class="hljs-number">.5</span>) * eps

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loss</span>(<span class="hljs-params">self, x0: torch.Tensor, noise: Optional[torch.Tensor] = <span class="hljs-literal">None</span></span>):</span>
        <span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">        #### Simplified Loss</span>
<span class="hljs-string">        $$L_simple(\theta) = \mathbb&#123;E&#125;_&#123;t,x_0, \epsilon&#125; \Bigg[ \bigg\Vert</span>
<span class="hljs-string">        \epsilon - \textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(\sqrt&#123;\bar\alpha_t&#125; x_0 + \sqrt&#123;1-\bar\alpha_t&#125;\epsilon, t)</span>
<span class="hljs-string">        \bigg\Vert^2 \Bigg]$$</span>
<span class="hljs-string">        &quot;&quot;&quot;</span>
        <span class="hljs-comment"># Get batch size</span>
        batch_size = x0.shape[<span class="hljs-number">0</span>]
        <span class="hljs-comment"># Get random $t$ for each sample in the batch</span>
        t = torch.randint(<span class="hljs-number">0</span>, self.n_steps, (batch_size,), device=x0.device, dtype=torch.long)

        <span class="hljs-comment"># $\epsilon \sim \mathcal&#123;N&#125;(\mathbf&#123;0&#125;, \mathbf&#123;I&#125;)$</span>
        <span class="hljs-keyword">if</span> noise <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
            noise = torch.randn_like(x0)

        <span class="hljs-comment"># Sample $x_t$ for $q(x_t|x_0)$</span>
        xt = self.q_sample(x0, t, eps=noise)
        <span class="hljs-comment"># Get $\textcolor&#123;cyan&#125;&#123;\epsilon_\theta&#125;(\sqrt&#123;\bar\alpha_t&#125; x_0 + \sqrt&#123;1-\bar\alpha_t&#125;\epsilon, t)$</span>
        eps_theta = self.eps_model(xt, t)

        <span class="hljs-comment"># MSE loss</span>
        <span class="hljs-keyword">return</span> F.mse_loss(noise, eps_theta)</code></pre></li>
</ol>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/03/31/DALL-E/">
                        <span class="hidden-mobile">DALL-E</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                
  <div id="SOHUCS" sid='http://example.com/2022/04/14/DDPM/'></div>
  <script type="text/javascript">
    Fluid.utils.waitElementVisible('SOHUCS', function() {
      var appid = 'cyvwVuPKH';
      var conf = 'f5f78350526f990216b0d5516cc87bca';
      var width = window.innerWidth || document.documentElement.clientWidth;
      if (width < 960) {
        window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="http://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>');
      } else {
        Fluid.utils.createScript("https://changyan.sohu.com/upload/changyan.js", function() {
          window.changyan.api.config({
            appid: appid,
            conf: conf
          })
        });
      }
    })
  </script>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a>
  </div>
  

  

  
</footer>

<!-- SCRIPTS -->

  <script  src="https://cdn.staticfile.org/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":200})
    NProgress.start()
    document.addEventListener('DOMContentLoaded', function() {
      window.NProgress && window.NProgress.inc();
    })
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.staticfile.org/jquery/3.5.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.5.3/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script  src="https://cdn.staticfile.org/tocbot/4.12.0/tocbot.min.js" ></script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>





  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      var inputArea = document.querySelector("#local-search-input");
      inputArea.onclick = function () {
        searchFunc(path, 'local-search-input', 'local-search-result');
        this.onclick = null
      }
    })()
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.1.2/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>



</body>
</html>
